---
title: "gpower_analysis_backup"
output: pdf_document
date: "2023-09-18"
---



``


```{r tableCharacteristics} 
# make Table 1 with article characteristics

# recode the $participants column
df1$participants <- factor(df1$participants, 
                           levels = c("Humans", "Non-human animals (this includes both in vivo and in vitro studies)"),
                           labels = c("Human", "Non-human animal")
)

# give the columns labels so that Table 1 is cleaner
label(df1$protocol) <- "Protocol"
label(df1$pub_year) <- "Year of publication"
label(df1$impact_factor) <- "Journal Impact Factor"
label(df1$participants) <- "Unit of study"
label(df1$multiple) <- "Multiple sample size calculations"

# make table 1
t1 <- table1(~ protocol +
               pub_year +
               impact_factor +
               participants +
               multiple,
             data = df1
)

## print t1 as Table 2.

####testing#####

# t2 <- table1(~ protocol +
#                pub_year +
#                impact_factor +
#                participants +
#                multiple +
#                as.factor(alpha_text) +
#                as.factor(power_text) +
#                effect_size_type +
#                stat_test +
#                reproducible +
#                mult_compare +
#                error +
#                match,
#                data = df1
# )

## print t2 as supplementary material. Maybe clean it up a tad. But it's going to serve to include all the information 

```

```{r tableOutcomes}
# recode columns to have fewer factors that will fit more cleanly into a table
df1 <- df1 %>% 
  mutate(all6_factor = 
           case_when(
             all6 == 6 ~ "Yes",
             TRUE ~ "No"
           ),
         alpha_factor = 
           case_when(
             alpha_text == 0.05 ~ "0.05",
             is.na(alpha_text) ~ "Not reported",
             TRUE ~ "Other"
           ),
         power_factor = 
           case_when(
             power_text == 0.8 ~ "0.80",
             power_text == 0.95 ~ "0.95",
             is.na(power_text) ~ "Not reported",
             TRUE ~ "Other"
           ),
         effect_size_type_factor = 
           case_when(
             effect_size_type == "d" ~ "d",
             effect_size_type == "f" ~ "f",
             effect_size_type == "Other: Non-standardized (e.g., 5 points on a questionnaire scale)." ~ "Non-standardized",
             effect_size_type == "No" ~ "Not reported",
             TRUE ~ "Other"
           ),
         effect_size_value_factor = 
           case_when(
             effect_size_value == 1 ~ "Reported",
             effect_size_value == 0 ~ "Not reported"
           ),  
         stat_test_factor = 
           case_when(
             stat_test == "ANOVA" ~ "ANOVA",
             stat_test == "t-test" ~ "t-test",
             stat_test == "the statistical test is NOT reported" ~ "Not reported",
             TRUE ~ "Other"
           ),
         # sample_size_factor = 
         #     case_when(
         #     sample_size_value == 1 ~ "Reported",
         #     sample_size_value == 0 ~ "Not reported"
         #     ),  
         reproducible_factor = 
           case_when(
             reproducible == "Yes, based solely on the information in the article or its supplementary material" ~ "Yes, without assumptions",
             reproducible== "Yes, but I've had to make some assumptions. (please list the assumptions you made)" ~ "Likely, with assumptions",
             reproducible == "No" ~ "No"
           ),
         mult_compare_factor = 
           case_when(
             grepl("contains multiple analyses", mult_compare) ~ "No, and multiple analyses are performed",
             grepl("no reason to account for multiple comparisons", mult_compare) ~ "No, but a single outcome was identified",
             mult_compare == "Unsure" ~ "Unsure",
             mult_compare == "Yes" ~ "Yes"
           ),
         error_factor = 
           case_when(
             grepl("Likely", error) ~ "Unsure",
             grepl("Unsure", error) ~ "Unsure",
             error == "No" ~ "No",
             error == "Yes" ~ "Yes" 
           ),
         match_factor = 
           case_when(
             grepl("Unsure", match) ~ "Unsure",
             match == "No" ~ "No",
             match == "Yes" ~ "Yes",
             grepl("protocol", match) ~ "NA (protocol)"
           )
  )

# order the levels of the factors for clarity
df1$all6_factor <- factor(df1$all6_factor, levels = c("Yes", "No"))
df1$alpha_factor <- factor(df1$alpha_factor, levels = c("0.05", "Other", "Not reported"))
df1$power_factor <- factor(df1$power_factor, levels = c("0.80", "0.95", "Other", "Not reported"))
df1$effect_size_type_factor <- factor(df1$effect_size_type_factor, levels = c("d", "f", "Non-standardized", "Other", "Not reported"))
df1$effect_size_value_factor <- factor(df1$effect_size_value_factor, levels = c("Reported", "Not reported"))
df1$stat_test_factor <- factor(df1$stat_test_factor, levels = c("ANOVA", "t-test", "Other", "Not reported"))
df1$reproducible_factor <- factor(df1$reproducible_factor, levels = c("Yes, without assumptions", "Likely, with assumptions", "No"))
df1$mult_compare_factor <- factor(df1$mult_compare_factor, levels = c("No, and multiple analyses are performed", "No, but a single outcome was identified", "Unsure", "Yes"))
df1$error_factor <- factor(df1$error_factor, levels = c("Yes", "No", "Unsure"))
df1$match_factor <- factor(df1$match_factor, levels = c("Yes", "No", "Unsure", "NA (protocol)"))

# label the columns so that Table 2 is cleaner
label(df1$all6_factor) <- "All 6 elements reported"
label(df1$alpha_factor) <- "Alpha"
label(df1$power_factor) <- "Power"
label(df1$effect_size_type_factor) <- "Effect size type"
label(df1$effect_size_value_factor) <- "Effect size value"
label(df1$stat_test_factor) <- "Statistical test"
label(df1$sample_size_text) <- "Sample size"
label(df1$reproducible_factor) <- "Reproducible"
label(df1$mult_compare_factor) <- "Adjusted for multiple comparisons"
label(df1$error_factor) <- "Error"
label(df1$match_factor) <- "Analysis match"

# df1$sample_size_text <- as.integer(df1$sample_size_text)
# that line didn't work to get rid of decimal places on "6.00" as the min sample size. 
# add IQR, its probably more meaningful than min and max.


t2 <- table1(~ all6_factor +
               reproducible_factor +
               alpha_factor + 
               power_factor + 
               effect_size_type_factor + 
               effect_size_value_factor +
               stat_test_factor +
               sample_size_text +
               mult_compare_factor +
               error_factor + 
               match_factor,
             data = df1,
             render.continuous=c(.="Median [IQR]"),
             digits.pct = 0, # to remove decimal places on percentages
             digits = 2 # to remove decimal places on median and IQR
)
t2

# Some power calculations had multiple justifications, so we need separate code for this column
justification <- rbind(
  sum(grepl("Previously published research", df1$justification)),
  sum(grepl("pilot data", df1$justification)),
  sum(grepl("Conventions", df1$justification)),
  sum(grepl("MCID", df1$justification)),
  sum(grepl("No justification", df1$justification)),
  sum(grepl("Reference to other study to justify their calculation in general", df1$justification)),
  sum(grepl("Other", df1$justification))
)

rownames(justification) <- c("Previous published research",
                             "Pilot data",
                             "Effect size conventions",
                             "Effect size of interest",
                             "No justification provided",
                             "Reference to another study, but not specifically to effect size",
                             "Other"
)
df1_repro <- df1 %>% filter(reproducible != "No")



```


```{r effectSizes}
# summarize the values for the 15 power calcs that were done with Cohen's d and the 15 with Cohen's f
dCohend <- df1 %>% 
  filter(effect_size_type == "d")
cohend <- summary(dCohend$effectSizeValue_text)

dCohenf <- df1 %>% 
  filter(effect_size_type == "f")
cohenf <- summary(dCohenf$effectSizeValue_text)

```

```{r}
tab <- 
  df1 %>% 
  summarize_at(c("version", 
                 "power", 
                 "alpha", 
                 "sample_size", 
                 "effect_size_typeBinary", 
                 "effectSizeValue", 
                 "stat_testBinary", 
                 "all6Binary"), 
               ~ ciCalc(sum(.), denom))

```

```{r}
t1


ciPower <- ciCalc(sum(df1$power), denom)
ciAlpha <- ciCalc(sum(df1$alpha), denom)
ciSampleSize <- ciCalc(sum(df1$sample_size), denom)
ciEffectSizeType <- ciCalc(sum(df1$effect_size_type != "No", na.rm = T), denom)
ciEffectSizeValue <- ciCalc(sum(df1$effectSizeValue), denom)
ciEffectSizeValue <- ciCalc(sum(df1$effectSizeValue), denom)


# MArton suggestion for making a table
# sum_table <- 
#   df1 %>% 
#   summarise(
#     ciPower = ciCalc(sum(power), denom),
# ciAlpha = ciCalc(sum(df1$alpha), denom),
# ciSampleSize = ciCalc(sum(df1$sample_size), denom),
# ciEffectSizeType = ciCalc(sum(df1$effect_size_type != "No", na.rm = T), denom),
# ciEffectSizeValue = ciCalc(sum(df1$effectSizeValue), denom),
# ciEffectSizeValue = ciCalc(sum(df1$effectSizeValue), denom),
#   )


ciPowerOut <- ciClean(ciPower)



```{r, Table1, include = TRUE, echo = FALSE, results = "asis"}
knitr::kable(cisOut, caption = "Table 1. Estimates of the number of published articles that use GPower", booktabs = T, linesep = "", align = "c") %>% 
  kable_styling(latex_options = "striped") %>%
  kable_styling(latex_options = c("hold_position")) %>%
  kable_styling(font_size = 8) %>% 
  add_footnote(paste0("The table is divided into articles that use G*Power for: any power calculation related to any statistical test (Any power calculation), a power calculation for any statistical test that solves for sample size (Sample size calculation), and a power calculation for an ANOVA that solves for sample size (ANOVA sample size calculation). The total number of articles in each database since 2017 is: PubMed Central ", prettyNum(pmcTotal, big.mark=",", scientific=F), "; PubMed ", prettyNum(pubmedTotal, big.mark=",", scientific=F), "."), notation = "none", threeparttable = T) 
```


  
  ## CODE to get preliminary results to the GPower team
  
  # filter for calculations solving for power
  d <- d %>% filter(grepl("Solves for sample size", powerCalcType))


reproducible <- table(d$reproducible)
power <- table(d$power)
alpha <- table(d$alpha)
effect_size_type <- table(d$alpha)
sample_size <- table(d$sample_size)
effectSizeValue <- table(d$effectSizeValue)
stat_test <- table(d$stat_test)
ANOVAwithinBetween <- table(d$ANOVAwithinBetween)
mult_compare <- table(d$mult_compare)
match <- table(d$match)
error <- table(d$error)



filepath <- paste0(getwd(), "/gpower_codingResolvingANOVAs_220929.csv" )
rawANOVA <- read.csv(filepath, header = TRUE)

dANOVA <- rawANOVA
# filter to only include resolved coding using with the keyword/charcter "/"
dANOVA <- dANOVA %>% filter(grepl("/", coder))
dANOVA <- dANOVA[1:9,]
ANOVAwithinBetweenANOVA <- table(dANOVA$ANOVAwithinBetween)


## prelim reproducibility results
Reproducible with assumptions: `r sum(grepl("Yes, but", d$reproducible))`

Reproducible without making assumptions: `r sum(grepl("Yes, based solely", d$reproducible))`

Not reproducible: `r sum(grepl("No", d$reproducible))`

Effect size value not reported: `r sum(grepl("No", d$effectSizeValue))`

Effect size type not reported: `r sum(grepl("No", d$effect_size_type))`

Statistical test not reported: `r sum(grepl("NOT reported", d$stat_test))`


```{r repro}

drep <- d %>% filter(grepl("Yes", reproducible))

reproducible_rep <- table(drep$reproducible)
power_rep <- table(drep$power)
alpha_rep <- table(drep$alpha)
effect_size_type_rep <- table(drep$effect_size_type)
sample_size_rep <- table(drep$sample_size)
effectSizeValue_rep <- table(drep$effectSizeValue)
stat_test_rep <- table(drep$stat_test)
ANOVAwithinBetween_rep <- table(drep$ANOVAwithinBetween)
mult_compare_rep <- table(drep$mult_compare)
match_rep <- table(drep$match)
error_rep <- table(drep$error)
```


```{r scrapped}

# label the columns so that Table 2 is cleaner
label(df1$reproducible_factor) <- "Reproducible"
label(df1$all6_factor) <- "All 6 elements reported"
label(df1$alpha_factor) <- "Alpha"
label(df1$power_factor) <- "Power"
label(df1$effect_size_type_factor) <- "Effect size type"
label(df1$effect_size_value_factor) <- "Effect size value"
label(df1$stat_test_factor) <- "Statistical test"
label(df1$sample_size_factor) <- "Sample size"
label(df1$mult_compare_factor) <- "Adjusted for multiple comparisons"
label(df1$error_factor) <- "Error"
label(df1$match_factor) <- "Analysis match"


ci_percent <- function(ci){
  ci <- ci %>% round(2) * 100
  if(ci[2] ==0){ci[2] <- "<1"}
  if(ci[3] ==0){ci[3] <- "<1"}
  ci_out <- paste0(ci[1], "%", " (", ci[2], " - ", ci[3], "%)")
  return(ci_out)
}
```
